{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "# Native\n",
    "import os\n",
    "import pickle\n",
    "from datetime import date\n",
    "\n",
    "# 3th party\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from progressbar import progressbar\n",
    "import os.path as osp\n",
    "import mmcv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8_2_morning_CE1_Spontaneous_Startle_rectified\n",
      "R_8_3_afternoon_loom_vidGP010125_012916_short\n",
      "8_5_CWcam_GP010019_15_32_s\n",
      "8_2_morning_CW_Spontaneous_Startle_rectified\n",
      "R_8_4_loom_w_cascade_vidGP020021_020542_short\n",
      "GOPR2207_s1\n",
      "8_2_morning_NE_Spontaneous_Startle_rectified\n",
      "8_3_morning_charge_GP015223_15_00_s\n",
      "8_4_lastvid\n",
      "8_2_morning_charge_GP020026_s\n",
      "GOPR0618_s\n",
      "8_2_morning_NW_Spontaneous_Startle_rectified\n",
      "R_8_4_loom_vidGP050021_031950_short\n",
      "8_4_GP050021\n",
      "8_2_morning_NR_cascade_group_GP040121_021930\n",
      "R_8_2_morning_loom_GP040121_021725_short\n",
      "8_5_NR_loom_w_singlebeat_020550\n",
      "8_5_CEcam2_GP035226_01_26_s\n",
      "8_5_CWcam_GP030019_00_23_s\n",
      "8_5_NR_loom_012053\n",
      "8_2_morning_charge_GP020026_09_29_s\n",
      "8_2_morning_CE2_Spontaneous_Startle_rectified\n",
      "GP062207_s\n",
      "GOPR2207_s2\n",
      "8_2_morning_charge02_02_34_45_s\n"
     ]
    }
   ],
   "source": [
    "# General setting\n",
    "today = date.today()\n",
    "today = today.strftime('%Y_%m_%d')\n",
    "\n",
    "\n",
    "# Directory settings\n",
    "origin_dir = \"../data/Moorea_labeled_data\"\n",
    "destination_dir = f\"../data/{today}_moorea\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R_8_4_loom_w_cascade_vidGP020021_020542_short', 'R_8_3_afternoon_loom_vidGP010125_012916_short', 'GOPR2207_s2', '8_4_GP050021', '8_3_morning_charge_GP015223_15_00_s', '8_2_morning_CW_Spontaneous_Startle_rectified', 'GP062207_s', 'R_8_2_morning_loom_GP040121_021725_short', '8_5_NR_loom_012053', '8_2_morning_NE_Spontaneous_Startle_rectified', '8_2_morning_NW_Spontaneous_Startle_rectified', '8_4_lastvid', '8_2_morning_charge_GP020026_09_29_s', '8_2_morning_charge02_02_34_45_s', '8_5_NR_loom_w_singlebeat_020550', '8_2_morning_CE2_Spontaneous_Startle_rectified', '8_2_morning_NR_cascade_group_GP040121_021930']\n",
      "['8_5_CEcam2_GP035226_01_26_s', 'R_8_4_loom_vidGP050021_031950_short', 'GOPR2207_s1', '8_2_morning_CE1_Spontaneous_Startle_rectified', '8_2_morning_charge_GP020026_s']\n",
      "['8_5_CWcam_GP030019_00_23_s', '8_5_CWcam_GP010019_15_32_s', 'GOPR0618_s']\n"
     ]
    }
   ],
   "source": [
    "vid_list = sorted(os.listdir(origin_dir))\n",
    "# vid_list = selected_vids\n",
    "\n",
    "# print(vid_list)\n",
    "train, test = train_test_split(vid_list, test_size=0.1, random_state=1)\n",
    "train, val = train_test_split(train, test_size=0.2, random_state=1)\n",
    "\n",
    "print(train)\n",
    "print(val)\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_moorea_data_folder(split, data_dir, destination_dir, out_file):\n",
    "    dest_img_dir = osp.join(destination_dir, \"images\")\n",
    "    # dest_label_dir = osp.join(destination_dir, \"labels\")\n",
    "    out_file = osp.join(destination_dir, out_file)\n",
    "    # Create directories if not exists\n",
    "    if not os.path.exists(destination_dir):\n",
    "        os.makedirs(destination_dir)\n",
    "        os.makedirs(dest_img_dir)\n",
    "        # os.makedirs(dest_label_dir)\n",
    "\n",
    "    annotations = []\n",
    "    images = []\n",
    "    obj_count = 0\n",
    "    img_count = 0\n",
    "    # annotation_dict = {}\n",
    "    for d in progressbar(sorted(split)):\n",
    "        images_dir = osp.join(data_dir, d, \"annotated_images\")\n",
    "        # print(d)\n",
    "        annotations_dir = osp.join(data_dir, d, \"annotations\")\n",
    "        annotations_file = osp.join(annotations_dir, f\"{d}_coco.json\")\n",
    "        # print(annotations_file)\n",
    "        with open(annotations_file, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "        # annotations.extend(data['annotations'])\n",
    "        # images.extend(data['images'])\n",
    "        \n",
    "        for i in data['images']:\n",
    "            # print(i['file_name'])\n",
    "            img_path = osp.join(images_dir, i['file_name'])\n",
    "            img = mmcv.imread(img_path)\n",
    "            mmcv.imwrite(img, osp.join(dest_img_dir, i['file_name']))\n",
    "            images.append(dict(\n",
    "                    id=img_count,\n",
    "                    file_name=i['file_name'],\n",
    "                    height=i['height'],\n",
    "                    width=i['width']))\n",
    "            for a in data['annotations']:\n",
    "                # print(a)\n",
    "                # print(i)\n",
    "                if a['image_id'] == i['id']:\n",
    "                    anno_obj = dict(\n",
    "                        image_id = img_count,\n",
    "                        id=obj_count,\n",
    "                        category_id=1,\n",
    "                        bbox=a['bbox'],\n",
    "                        area=a['area'],\n",
    "                        segmentation=a['segmentation'],\n",
    "                        iscrowd=0\n",
    "                    )\n",
    "                    annotations.append(anno_obj)\n",
    "                    obj_count += 1\n",
    "            img_count += 1\n",
    "\n",
    "    coco_dict = dict(\n",
    "        images=images,\n",
    "        annotations=annotations,\n",
    "        categories=data['categories'],\n",
    "        info=data['info'])\n",
    "    mmcv.dump(coco_dict, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (17 of 17) |########################| Elapsed Time: 0:00:15 Time:  0:00:15\n",
      "100% (3 of 3) |##########################| Elapsed Time: 0:00:02 Time:  0:00:02\n",
      "100% (5 of 5) |##########################| Elapsed Time: 0:00:03 Time:  0:00:03\n"
     ]
    }
   ],
   "source": [
    "convert_moorea_data_folder(train, origin_dir, destination_dir, \"train_coco.json\")\n",
    "convert_moorea_data_folder(test, origin_dir, destination_dir, \"test_coco.json\")\n",
    "convert_moorea_data_folder(val, origin_dir, destination_dir, \"val_coco.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all subdir\n",
    "def convert_fish_tracking_to_coco(split, data_dir, destination_dir, out_file):\n",
    "    dest_img_path = osp.join(destination_dir, \"images\")\n",
    "    dest_label_path = osp.join(destination_dir, \"labels\")\n",
    "    out_file = osp.join(destination_dir, out_file)\n",
    "    # Create directories if not exists\n",
    "    if not os.path.exists(destination_dir):\n",
    "        os.makedirs(destination_dir)\n",
    "        os.makedirs(dest_img_path)\n",
    "        os.makedirs(dest_label_path)\n",
    "\n",
    "\n",
    "    annotations = []\n",
    "    images = []\n",
    "    obj_count = 0\n",
    "    # osp.join(data_dir, split)\n",
    "    for d in progressbar(sorted(split)):\n",
    "        # print(d)\n",
    "        # print(data_dir)\n",
    "        sub_dir = osp.join(data_dir, d)\n",
    "        video_path = osp.join(sub_dir, video_dir)\n",
    "        annotation_path = osp.join(sub_dir, label_dir)\n",
    "    \n",
    "        for angle in camera_angles:\n",
    "            annotation_file = osp.join(annotation_path, f\"{d}Corr{angle}.pkl\")\n",
    "            annotation_dict = pickle.load(open(annotation_file, \"rb\"))\n",
    "\n",
    "            # Load video\n",
    "            video_file = os.path.join(video_path, f\"{d}_{angle}.mp4\")\n",
    "            cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "            i = 0\n",
    "            for x,y in zip(annotation_dict[\"0\"][\"X\"],annotation_dict[\"0\"][\"Y\"]):\n",
    "            \n",
    "                ret, frame = cap.read()\n",
    "\n",
    "                if np.isnan(x) or np.isnan(y):\n",
    "                    continue\n",
    "                \n",
    "                x_min = int(x) - radius\n",
    "                y_min = int(y) - radius\n",
    "                x_max = int(x) + radius\n",
    "                y_max = int(y) + radius\n",
    "\n",
    "                # Get frame size\n",
    "                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH ))\n",
    "                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT ))\n",
    "                # fps =  cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "                image = frame\n",
    "\n",
    "                # Naming scheme\n",
    "                idx = str(i)\n",
    "                idx = idx.zfill(5) \n",
    "                image_name = f\"{d}_{angle}_{idx}\"\n",
    "                \n",
    "                # Write img\n",
    "                cv2.imwrite(f\"{dest_img_path}/{image_name}.jpg\", image)\n",
    "                \n",
    "                images.append(dict(\n",
    "                    id=obj_count,\n",
    "                    file_name=f\"{image_name}.jpg\",\n",
    "                    height=height,\n",
    "                    width=width))\n",
    "                # write label\n",
    "                \n",
    "                label = [\"predator\", \"0\", x_min, y_min, x_max, y_max, width, height]\n",
    "                with open(f'{dest_label_path}/{image_name}.txt', 'w') as f:\n",
    "                    for item in label:\n",
    "                        f.write(\"%s \" % item)\n",
    "                \n",
    "                data_anno = dict(\n",
    "                    image_id=obj_count,\n",
    "                    id=obj_count,\n",
    "                    category_id=0,\n",
    "                    bbox=[x_min, y_min, x_max - x_min, y_max - y_min],\n",
    "                    area=(x_max - x_min) * (y_max - y_min),\n",
    "                    # segmentation=[],\n",
    "                    iscrowd=0)\n",
    "                annotations.append(data_anno)\n",
    "                \n",
    "                i+= 1\n",
    "                obj_count+= 1 \n",
    "    \n",
    "    coco_format_json = dict(\n",
    "        images=images,\n",
    "        annotations=annotations,\n",
    "        categories=[{'id':0, 'name': 'predator'}])\n",
    "    mmcv.dump(coco_format_json, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convert_fish_tracking_to_coco' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/casper/uva/fish_detection/notebooks/moorea_coco_parser.ipynb Cell 7'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/casper/uva/fish_detection/notebooks/moorea_coco_parser.ipynb#ch0000004?line=0'>1</a>\u001b[0m convert_fish_tracking_to_coco(train, origin_dir, destination_dir, \u001b[39m\"\u001b[39m\u001b[39mtrain_coco.json\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/casper/uva/fish_detection/notebooks/moorea_coco_parser.ipynb#ch0000004?line=1'>2</a>\u001b[0m convert_fish_tracking_to_coco(test, origin_dir, destination_dir, \u001b[39m\"\u001b[39m\u001b[39mtest_coco.json\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/casper/uva/fish_detection/notebooks/moorea_coco_parser.ipynb#ch0000004?line=2'>3</a>\u001b[0m convert_fish_tracking_to_coco(val, origin_dir, destination_dir, \u001b[39m\"\u001b[39m\u001b[39mval_coco.json\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'convert_fish_tracking_to_coco' is not defined"
     ]
    }
   ],
   "source": [
    "convert_fish_tracking_to_coco(train, origin_dir, destination_dir, \"train_coco.json\")\n",
    "convert_fish_tracking_to_coco(test, origin_dir, destination_dir, \"test_coco.json\")\n",
    "convert_fish_tracking_to_coco(val, origin_dir, destination_dir, \"val_coco.json\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "94786822783e74b9855c6170cf43bb522c9afd9533ac6fefda5b6074988df35a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('mmdetection')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
